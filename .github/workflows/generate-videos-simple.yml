name: Generate Lecture Videos (Simple)

on:
  workflow_dispatch:
    inputs:
      lecture_filter:
        description: 'Generate videos for specific lectures (e.g., "lecture1,lecture2" or "all")'
        required: false
        default: 'all'
        type: string
      force_regenerate:
        description: 'Force regeneration of scripts and videos even if they exist'
        required: false
        default: false
        type: boolean

permissions:
  contents: write

jobs:
  generate-videos:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Get full history for change detection
        
    - name: Check voice sample
      run: |
        if [ -f "my-voice-sample.wav" ]; then
          echo "✅ Voice sample file found"
        else
          echo "⚠️  Voice sample file 'my-voice-sample.wav' not found - videos will use default voice"
        fi
      
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y ffmpeg poppler-utils
        pip install google-generativeai requests pdf2image pillow
        
    - name: Create and run video generation script
      run: |
        cat > generate_videos.py << 'EOF'
        import os
        import sys
        import time
        import hashlib
        import subprocess
        import json
        from pathlib import Path
        from pdf2image import convert_from_path
        import google.generativeai as genai
        import requests
        
        class LectureVideoGenerator:
            def __init__(self):
                self.setup_apis()
                self.videos_dir = Path("videos")
                self.temp_dir = Path("temp_video_generation")
                self.cache_file = Path("video_generation_cache.json")
                self.scripts_dir = Path("scripts")
                self.voice_sample = Path("my-voice-sample.wav")
                self.cloned_voice_id = None
                
                self.videos_dir.mkdir(exist_ok=True)
                self.temp_dir.mkdir(exist_ok=True)
                self.scripts_dir.mkdir(exist_ok=True)
                self.cache = self.load_cache()
                self.setup_voice_cloning()
                
            def setup_apis(self):
                if not os.getenv('GOOGLE_AI_STUDIO_API_KEY'):
                    raise ValueError("GOOGLE_AI_STUDIO_API_KEY required")
                if not os.getenv('MINIMAX_API_KEY'):
                    raise ValueError("MINIMAX_API_KEY required")
                    
                genai.configure(api_key=os.getenv('GOOGLE_AI_STUDIO_API_KEY'))
                self.model = genai.GenerativeModel('gemini-2.5-pro')
                self.minimax_api_key = os.getenv('MINIMAX_API_KEY')
                self.minimax_group_id = os.getenv('MINIMAX_GROUP_ID')
                print("APIs configured")
                
            def setup_voice_cloning(self):
                """Setup voice cloning using the user's cloned voice"""
                print("🎤 Setting up voice cloning...")
                
                # Use the user's current cloned voice ID
                self.cloned_voice_id = "danielVoice15092025"
                print(f"✅ Using cloned voice: {self.cloned_voice_id}")
                
                # Check if voice sample exists for reference
                if self.voice_sample.exists():
                    print(f"📁 Voice sample file found: {self.voice_sample}")
                else:
                    print("⚠️  Voice sample file not found, but using existing clone")
                
                return True
                
            def load_cache(self):
                if self.cache_file.exists():
                    with open(self.cache_file, 'r') as f:
                        return json.load(f)
                return {}
                
            def save_cache(self):
                with open(self.cache_file, 'w') as f:
                    json.dump(self.cache, f, indent=2)
                    
            def get_pdf_hash(self, pdf_path):
                with open(pdf_path, 'rb') as f:
                    return hashlib.md5(f.read()).hexdigest()
                    
            def should_regenerate_video(self, lecture_name, pdf_path, force=False):
                if force:
                    return True
                    
                video_path = self.videos_dir / f"{lecture_name}.mp4"
                if not video_path.exists():
                    return True
                    
                current_hash = self.get_pdf_hash(pdf_path)
                cached_hash = self.cache.get(lecture_name, {}).get('pdf_hash')
                return current_hash != cached_hash
                
            def extract_slides_from_pdf(self, pdf_path, lecture_name):
                print(f"Extracting slides from {pdf_path}")
                slides_dir = self.temp_dir / lecture_name / "slides"
                slides_dir.mkdir(parents=True, exist_ok=True)
                
                images = convert_from_path(pdf_path, dpi=300, fmt='PNG')
                slide_paths = []
                for i, image in enumerate(images):
                    slide_path = slides_dir / f"slide_{i+1:03d}.png"
                    image.save(slide_path, 'PNG')
                    slide_paths.append(slide_path)
                    
                print(f"Extracted {len(slide_paths)} slides")
                return slide_paths
                
            def generate_script_with_gemini(self, pdf_path, force_regenerate=False):
                lecture_name = pdf_path.stem
                scripts_dir = Path('scripts')
                scripts_dir.mkdir(exist_ok=True)
                script_file_path = scripts_dir / f"{lecture_name}_script.json"
                
                if script_file_path.exists() and not force_regenerate:
                    print(f"Loading existing script from {script_file_path}")
                    try:
                        with open(script_file_path, 'r', encoding='utf-8') as f:
                            script_data = json.load(f)
                        scripts = {}
                        for item in script_data.get('scripts', []):
                            if isinstance(item, dict) and 'slide' in item and 'script' in item:
                                scripts[item['slide']] = item['script']
                        print(f"Loaded scripts for {len(scripts)} slides")
                        return scripts
                    except Exception as e:
                        print(f"Error loading script: {e}")
                
                print("Generating script with Gemini...")
                with open(pdf_path, 'rb') as f:
                    pdf_data = f.read()
                
                prompt = """Create narration scripts for each slide in this PDF lecture presentation.
                
                Requirements:
                - Academic tone for university students
                - 15-30 seconds per slide
                - Natural pauses between slides
                - Format: Slide 1: [narration text]
                
                And so on for each slide."""
                
                # Retry logic with optimized model fallback order
                models = ["gemini-2.5-pro", "gemini-2.5-flash", "gemini-1.5-flash", "gemini-1.5-flash-latest"]
                last_error = None
                for model_name in models:
                    print(f"Attempting Gemini generation with model: {model_name}")
                    try:
                        # Reconfigure model dynamically
                        self.model = genai.GenerativeModel(model_name)
                        # The SDK will base64 encode raw bytes automatically when passed this dict
                        response = self.model.generate_content([
                            prompt,
                            {"mime_type": "application/pdf", "data": pdf_data}
                        ])
                        script = response.text or ""
                        print("Generated script with Gemini")
                        print(f"Gemini response length: {len(script)}")
                        print(f"First 500 chars: {script[:500]}")
                        scripts = self.parse_script(script)
                        print(f"Parsed {len(scripts)} scripts from Gemini response")
                        if not scripts:
                            print("Script parsing failed, using fallback text scaffolding")
                            images = convert_from_path(pdf_path, dpi=150)
                            scripts = {i: f"This is slide {i} of the presentation." for i in range(1, len(images)+1)}
                            print(f"Created {len(scripts)} basic scripts")
                        if scripts:
                            script_list = [
                                {"slide": slide_num, "script": script_text}
                                for slide_num, script_text in scripts.items()
                            ]
                            script_data = {
                                'lecture_name': lecture_name,
                                'generated_at': time.strftime('%Y-%m-%d %H:%M:%S'),
                                'total_slides': len(scripts),
                                'scripts': script_list,
                                'raw_gemini_response': script[:1000] + "..." if len(script) > 1000 else script,
                                'model_used': model_name,
                                'force_regenerated': force_regenerate
                            }
                            with open(script_file_path, 'w', encoding='utf-8') as f:
                                json.dump(script_data, f, indent=2, ensure_ascii=False)
                            print(f"Scripts saved to {script_file_path}")
                        return scripts
                    except Exception as e:
                        last_error = e
                        # Handle rate limit or transient errors with backoff
                        msg = str(e)
                        if '429' in msg or 'quota' in msg.lower():
                            wait = 15
                            print(f"Rate limit/quota hit for {model_name}. Backing off {wait}s then trying next model...")
                            time.sleep(wait)
                        else:
                            print(f"Model {model_name} failed: {e}")
                print(f"All Gemini model attempts failed. Last error: {last_error}")
                return None
                    
            def parse_script(self, script_text):
                print("=== GEMINI RESPONSE DEBUGGING ===")
                print(f"Response length: {len(script_text)}")
                print("First 800 characters:")
                print(script_text[:800])
                print("=== END DEBUGGING ===")
                
                scripts = {}
                current_slide = None
                current_text = []
                
                for line_num, line in enumerate(script_text.split('\n')):
                    line = line.strip()
                    
                    # Handle markdown bold format: **Slide 1:**
                    if '**Slide ' in line and ':**' in line:
                        if current_slide and current_text:
                            scripts[current_slide] = ' '.join(current_text).strip()
                        
                        # Extract slide number from **Slide X:**
                        parts = line.split(':**', 1)
                        slide_part = parts[0].replace('**Slide ', '').strip()
                        try:
                            current_slide = int(slide_part)
                            current_text = [parts[1].strip()] if len(parts) > 1 and parts[1].strip() else []
                            print(f"Found slide {current_slide} (markdown format)")
                        except ValueError:
                            print(f"Could not parse slide: {slide_part}")
                            continue
                    
                    # Handle regular format: Slide 1:
                    elif line.startswith('Slide ') and ':' in line:
                        if current_slide and current_text:
                            scripts[current_slide] = ' '.join(current_text).strip()
                        
                        parts = line.split(':', 1)
                        slide_part = parts[0].replace('Slide ', '').strip()
                        try:
                            current_slide = int(slide_part)
                            current_text = [parts[1].strip()] if len(parts) > 1 and parts[1].strip() else []
                            print(f"Found slide {current_slide} (regular format)")
                        except ValueError:
                            print(f"Could not parse slide: {slide_part}")
                            continue
                            
                    elif line and line[0].isdigit() and (':' in line or '.' in line):
                        separator = ':' if ':' in line else '.'
                        parts = line.split(separator, 1)
                        
                        try:
                            slide_num = int(parts[0].strip())
                            
                            if current_slide and current_text:
                                scripts[current_slide] = ' '.join(current_text).strip()
                            
                            current_slide = slide_num
                            current_text = [parts[1].strip()] if len(parts) > 1 and parts[1].strip() else []
                            print(f"Found slide {current_slide} (number format)")
                        except (ValueError, IndexError):
                            if current_slide and line:
                                current_text.append(line)
                                
                    elif current_slide and line and not line.startswith('**') and not line.startswith('***'):
                        # Skip markdown formatting lines but keep content
                        current_text.append(line)
                
                if current_slide and current_text:
                    scripts[current_slide] = ' '.join(current_text).strip()
                    
                print(f"Found {len(scripts)} slides")
                for slide_num in sorted(scripts.keys())[:3]:
                    preview = scripts[slide_num][:100] + "..." if len(scripts[slide_num]) > 100 else scripts[slide_num]
                    print(f"Slide {slide_num}: {preview}")
                    
                return scripts
                
            def generate_audio_with_minimax(self, text, slide_num, lecture_name):
                """Generate audio using MiniMax TTS API"""
                voice_type = "cloned voice" if self.cloned_voice_id else "default voice"
                print(f"🎵 Generating audio for slide {slide_num} using {voice_type}")
                
                base_url = "https://api.minimax.io/v1/t2a_v2"
                
                if self.minimax_group_id:
                    url = f"{base_url}?GroupId={self.minimax_group_id}"
                    print(f"Using voice cloning with group_id: {self.minimax_group_id}")
                else:
                    url = base_url
                    print("Using default voice")
                
                headers = {
                    "Authorization": f"Bearer {self.minimax_api_key}",
                    "Content-Type": "application/json"
                }
                
                payload = {
                    "model": "speech-2.5-hd-preview",
                    "text": text,
                    "stream": False,
                    "voice_setting": {
                        "voice_id": self.cloned_voice_id if self.cloned_voice_id else "male-qn-qingse",
                        "speed": 1.0,
                        "vol": 1.0,
                        "pitch": 0
                    },
                    "audio_setting": {
                        "sample_rate": 32000,
                        "bitrate": 128000,
                        "format": "mp3",
                        "channel": 1
                    }
                }
                
                try:
                    response = requests.post(url, headers=headers, json=payload, timeout=60)
                    response.raise_for_status()
                    
                    result = response.json()
                    print(f"MiniMax API response keys: {list(result.keys())}")
                    print(f"MiniMax API response (first 500 chars): {str(result)[:500]}")
                    
                    # Check for successful response
                    base_resp = result.get("base_resp", {})
                    if base_resp.get("status_code") != 0:
                        print(f"MiniMax API error: {base_resp.get('status_msg', 'Unknown error')}")
                        return None
                    
                    # Extract audio from data.audio (hex format)
                    data = result.get("data", {})
                    if isinstance(data, dict) and "audio" in data:
                        audio_hex = data["audio"]
                        print(f"Found hex audio data (length: {len(audio_hex)})")
                        try:
                            audio_bytes = bytes.fromhex(audio_hex)
                            print("Successfully decoded hex audio")
                        except ValueError as e:
                            print(f"Failed to decode hex audio: {e}")
                            return None
                    else:
                        print(f"No audio data found in response data: {list(data.keys()) if isinstance(data, dict) else type(data)}")
                        return None
                    
                    audio_path = self.temp_dir / lecture_name / f"audio_slide_{slide_num:03d}.mp3"
                    audio_path.parent.mkdir(parents=True, exist_ok=True)
                    
                    with open(audio_path, 'wb') as f:
                        f.write(audio_bytes)
                    
                    print(f"Generated audio for slide {slide_num}")
                    return audio_path
                        
                except requests.RequestException as e:
                    print(f"Error calling MiniMax API: {e}")
                    if hasattr(e, 'response') and e.response:
                        print(f"Response: {e.response.text}")
                    return None
                        
                except Exception as e:
                    print(f"Error generating audio: {e}")
                    return None
                    
            def create_video_with_ffmpeg(self, slide_paths, audio_paths, lecture_name):
                """Create video using FFmpeg"""
                print(f"Creating video for {lecture_name}")
                print(f"Slide paths: {len(slide_paths)}, Audio paths: {len(audio_paths)}")
                
                valid_pairs = [(slide_path, audio_path) for slide_path, audio_path in zip(slide_paths, audio_paths) if audio_path and audio_path.exists()]
                print(f"Valid pairs: {len(valid_pairs)}")
                
                if not valid_pairs:
                    print("No valid audio files")
                    return None
                
                temp_videos = []
                for i, (slide_path, audio_path) in enumerate(valid_pairs):
                    print(f"Processing slide {i+1}")
                    
                    duration_cmd = [
                        'ffprobe', '-v', 'quiet', '-show_entries', 'format=duration',
                        '-of', 'csv=p=0', str(audio_path)
                    ]
                    try:
                        duration_output = subprocess.check_output(duration_cmd).decode().strip()
                        duration = float(duration_output)
                        if duration <= 0:
                            duration = 3.0
                    except Exception as e:
                        print(f"Could not get duration: {e}")
                        duration = 3.0
                    
                    print(f"Duration: {duration}s")
                    
                    temp_video = self.temp_dir / lecture_name / f"segment_{i:03d}.mp4"
                    temp_video.parent.mkdir(parents=True, exist_ok=True)
                    
                    cmd = [
                        'ffmpeg', '-y',
                        '-loop', '1', '-t', str(duration), '-i', str(slide_path),
                        '-i', str(audio_path),
                        '-c:v', 'libx264', '-crf', '23', '-preset', 'medium',
                        '-c:a', 'aac', '-b:a', '128k',
                        '-vf', 'scale=1920:1080:force_original_aspect_ratio=decrease,pad=1920:1080:(ow-iw)/2:(oh-ih)/2',
                        '-shortest',
                        str(temp_video)
                    ]
                    
                    print(f"Running FFmpeg for segment {i+1}")
                    try:
                        result = subprocess.run(cmd, check=True, capture_output=True)
                        temp_videos.append(temp_video)
                        print(f"Created segment {i+1}/{len(valid_pairs)}")
                    except subprocess.CalledProcessError as e:
                        print(f"Error creating segment {i}: {e}")
                        return None
                
                if len(temp_videos) == 1:
                    output_path = self.videos_dir / f"{lecture_name}.mp4"
                    subprocess.run(['cp', str(temp_videos[0]), str(output_path)], check=True)
                else:
                    concat_file = self.temp_dir / lecture_name / "concat.txt"
                    with open(concat_file, 'w') as f:
                        for video in temp_videos:
                            f.write(f"file '{video.absolute()}'\n")
                    
                    output_path = self.videos_dir / f"{lecture_name}.mp4"
                    cmd = [
                        'ffmpeg', '-y',
                        '-f', 'concat', '-safe', '0', '-i', str(concat_file),
                        '-c', 'copy',
                        '-movflags', '+faststart',
                        str(output_path)
                    ]
                    
                    try:
                        subprocess.run(cmd, check=True, capture_output=True)
                    except subprocess.CalledProcessError as e:
                        print(f"Error concatenating: {e}")
                        return None
                
                print(f"Created video: {output_path}")
                return output_path
                    
            def process_lecture(self, pdf_path, force_regenerate=False):
                lecture_name = pdf_path.stem
                print(f"\n=== Processing {lecture_name} ===")
                
                if not self.should_regenerate_video(lecture_name, pdf_path, force_regenerate):
                    print(f"Video up to date, skipping")
                    return True
                
                try:
                    print(f"Extracting slides from PDF...")
                    slide_paths = self.extract_slides_from_pdf(pdf_path, lecture_name)
                    print(f"Extracted {len(slide_paths)} slides")
                    
                    print(f"Generating scripts with Gemini...")
                    scripts = self.generate_script_with_gemini(pdf_path, force_regenerate)
                    print(f"Generated scripts for {len(scripts) if scripts else 0} slides")
                    
                    if not scripts:
                        print("No scripts generated, cannot continue")
                        return False
                    
                    print(f"Generating audio for {len(scripts)} slides...")
                    audio_paths = []
                    for i, slide_path in enumerate(slide_paths, 1):
                        if i in scripts:
                            print(f"Generating audio for slide {i}...")
                            audio_path = self.generate_audio_with_minimax(scripts[i], i, lecture_name)
                            audio_paths.append(audio_path)
                            if audio_path:
                                print(f"Audio generated for slide {i}")
                            else:
                                print(f"Audio generation failed for slide {i}")
                            time.sleep(1)
                        else:
                            print(f"No script for slide {i}")
                            audio_paths.append(None)
                    
                    valid_audio = [p for p in audio_paths if p is not None]
                    print(f"Generated {len(valid_audio)}/{len(audio_paths)} audio files")
                    
                    if not valid_audio:
                        print("No audio files generated, cannot create video")
                        return False
                    
                    print(f"Creating video...")
                    video_path = self.create_video_with_ffmpeg(slide_paths, audio_paths, lecture_name)
                    
                    if video_path:
                        self.cache[lecture_name] = {
                            'pdf_hash': self.get_pdf_hash(pdf_path),
                            'video_path': str(video_path),
                            'generated_at': time.time()
                        }
                        self.save_cache()
                        print(f"Successfully processed {lecture_name}")
                        return True
                    else:
                        print(f"Video creation failed for {lecture_name}")
                        return False
                    
                except Exception as e:
                    print(f"Error processing {lecture_name}: {e}")
                    import traceback
                    traceback.print_exc()
                    return False
                
            def cleanup_temp_files(self):
                import shutil
                if self.temp_dir.exists():
                    shutil.rmtree(self.temp_dir)
                    
        def main():
            generator = LectureVideoGenerator()
            
            lecture_filter = os.getenv('LECTURE_FILTER', 'all')
            force_regenerate = os.getenv('FORCE_REGENERATE', 'false').lower() == 'true'
            
            pdfs_dir = Path("pdfs")
            pdf_files = list(pdfs_dir.glob("lecture*.pdf"))
            
            if not pdf_files:
                print("No PDFs found")
                return
            
            if lecture_filter != 'all':
                filter_names = [name.strip() for name in lecture_filter.split(',')]
                pdf_files = [pdf for pdf in pdf_files if any(filter_name in pdf.stem for filter_name in filter_names)]
            
            print(f"Processing {len(pdf_files)} PDFs: {[pdf.stem for pdf in pdf_files]}")
            
            success_count = 0
            for pdf_path in pdf_files:
                if generator.process_lecture(pdf_path, force_regenerate):
                    success_count += 1
            
            print(f"\n=== Summary ===")
            print(f"Processed: {success_count}/{len(pdf_files)} lectures")
            generator.cleanup_temp_files()
            
        if __name__ == "__main__":
            main()
        EOF
        
        python generate_videos.py
      env:
        GOOGLE_AI_STUDIO_API_KEY: ${{ secrets.GOOGLE_AI_STUDIO_API_KEY }}
        MINIMAX_API_KEY: ${{ secrets.MINIMAX_API_KEY }}
        MINIMAX_GROUP_ID: ${{ secrets.MINIMAX_GROUP_ID }}
        LECTURE_FILTER: ${{ inputs.lecture_filter }}
        FORCE_REGENERATE: ${{ inputs.force_regenerate }}
        
    - name: Create videos README
      run: |
        cat > videos/README.md << 'EOF'
        # AI-Generated Lecture Videos
        
        This directory contains automatically generated videos for the AIAP lecture slides.
        
        ## How Videos Are Generated
        
        1. **PDF Processing**: Each lecture PDF is processed by Google Gemini AI
        2. **Script Generation**: Gemini creates educational narration scripts for each slide
        3. **Voice Synthesis**: MiniMax TTS generates audio using voice cloning
        4. **Video Assembly**: FFmpeg combines slides and audio into final videos
        
        ## Available Videos
        
        EOF
        
        for file in videos/*.mp4; do
          if [ -f "$file" ]; then
            filename=$(basename "$file" .mp4)
            echo "- [${filename}](./${filename}.mp4)" >> videos/README.md
          fi
        done
        
        if ! ls videos/*.mp4 1> /dev/null 2>&1; then
          echo "- No videos available yet" >> videos/README.md
        fi
        
        cat >> videos/README.md << 'EOF'
        
        ## Video Specifications
        
        - **Resolution**: 1920x1080 (Full HD)
        - **Format**: MP4 (H.264 video, AAC audio)
        - **Frame Rate**: Variable (based on audio duration)
        - **Audio**: AI-generated narration with voice cloning
        
        ## Regeneration
        
        Videos are automatically regenerated when:
        - The source PDF is updated
        - Manual regeneration is triggered via GitHub Actions
        
        ---
        
        *Videos generated automatically using AI tools*
        EOF
        
    - name: Commit generated content
      run: |
        # Configure Git for commits
        git config user.name "Daniel Cregg"
        git config user.email "danielcregg@users.noreply.github.com"
        git config commit.gpgsign false
        
        if [ -d "videos" ]; then
          git add videos/
        fi
        if [ -d "scripts" ]; then
          git add scripts/
        fi
        if [ -f "video_generation_cache.json" ]; then
          git add video_generation_cache.json
        fi
        
        if git diff --staged --quiet; then
          echo "No changes to commit"
        else
          git commit -m "Auto-generate lecture videos and scripts [skip ci]" || exit 0
          git push
        fi
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        
    - name: Trigger README update for videos
      run: |
        # Create a trigger file to let the README update workflow know videos were generated
        echo "Video generation completed at $(date)" >> .video-generation-log
        git add .video-generation-log
        git commit -m "Trigger README update after video generation" || exit 0
        git push
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
